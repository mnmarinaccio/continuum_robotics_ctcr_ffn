Six Hidden Layers - Sizes = [64, 96, 50, 25, 18, 15]
Leaky ReLU Activation
ADAM Optimizer 
MSE Loss

Train - 80000 Points
Validation - 10000 Points
Test - 10000 Points

Input:

Some Features = Only position and orientation for frames (x#, y#, z#, n#, sigma##) except for x3 and beyond
All Features = Everything up until x3 column

Predictions for [x3, y3, z3, n3, sigma31, sigma32, sigma33]



class Model(nn.Module):
    def __init__(self, in_features=33, h1=64, h2=96, h3=50, h4=25, h5=18, h6=15, out_features=7):
        super().__init__()
        self.fc1 = nn.Linear(in_features, h1)
        self.fc2 = nn.Linear(h1, h2)
        self.fc3 = nn.Linear(h2, h3)
        self.fc4 = nn.Linear(h3, h4)
        self.fc5 = nn.Linear(h4, h5)
        self.fc6 = nn.Linear(h5, h6)
        self.out = nn.Linear(h6, out_features)
    
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x))
        x = F.leaky_relu(self.fc2(x))
        x = F.leaky_relu(self.fc3(x))
        x = F.leaky_relu(self.fc4(x))
        x = F.leaky_relu(self.fc5(x))
        x = F.leaky_relu(self.fc6(x))
        x = self.out(x)
        
        return x

